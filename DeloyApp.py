import streamlit as st
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report
from joblib import load, dump
import mlflow
import mlflow.sklearn
import os
from mlflow.models.signature import infer_signature
import numpy as np


# Äá»c dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
X_train = pd.read_csv("processed_data/X_train.csv")
X_valid = pd.read_csv("processed_data/X_valid.csv")
X_test = pd.read_csv("processed_data/X_test.csv")
y_train = pd.read_csv("processed_data/y_train.csv").squeeze()
y_valid = pd.read_csv("processed_data/y_valid.csv").squeeze()
y_test = pd.read_csv("processed_data/y_test.csv").squeeze()

# Cáº¥u hÃ¬nh MLflow
mlflow.set_experiment("RandomForest_Classification")

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Cross Validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cross_val_results = cross_val_score(rf_model, X_train, y_train, cv=cv, scoring='accuracy')

# ========================== HÃ€M Há»– TRá»¢ ==========================

def load_model_from_file(model_path):
    """ Load mÃ´ hÃ¬nh tá»« file, kiá»ƒm tra náº¿u tá»“n táº¡i. """
    if os.path.exists(model_path):
        return load(model_path)
    else:
        st.error(f"ğŸš¨ KhÃ´ng tÃ¬m tháº¥y file mÃ´ hÃ¬nh: {model_path}")
        return None

def preprocess_input(pclass, sex, age, sibsp, parch, fare, embarked):
    """ Tiá»n xá»­ lÃ½ Ä‘áº§u vÃ o cho mÃ´ hÃ¬nh. """
    sex = 0 if sex == "Male" else 1
    embarked = {"S": 0, "C": 1, "Q": 2}.get(embarked, -1)
    input_data = np.array([[pclass, sex, age, sibsp, parch, fare, embarked]], dtype=np.float64)
    return input_data

def get_mlflow_runs():
    """ Láº¥y danh sÃ¡ch cÃ¡c láº§n cháº¡y tá»« MLflow """
    try:
        runs = mlflow.search_runs()
        return runs
    except Exception as e:
        st.error(f"ğŸš¨ Lá»—i khi láº¥y dá»¯ liá»‡u tá»« MLflow: {e}")
        return None

def main():
    st.set_page_config(layout="wide")  
    st.title("ğŸ“Š á»¨ng dá»¥ng PhÃ¢n TÃ­ch Dá»¯ Liá»‡u & Dá»± ÄoÃ¡n")

    tab1, tab2, tab3 = st.tabs(["ğŸ“‚ Xá»­ lÃ½ dá»¯ liá»‡u", "ğŸ“ˆ Huáº¥n luyá»‡n mÃ´ hÃ¬nh", "ğŸ¤– Dá»± Ä‘oÃ¡n"])

    # ========================== TAB 1: Xá»¬ LÃ Dá»® LIá»†U ==========================
    with tab1:
        st.header("ğŸ”„ QuÃ¡ trÃ¬nh Xá»­ lÃ½ Dá»¯ liá»‡u")

        # Táº£i dá»¯ liá»‡u Titanic tá»« URL
        url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
        df = pd.read_csv(url)

        # **1ï¸âƒ£ Hiá»ƒn thá»‹ Dá»¯ liá»‡u Gá»‘c**
        st.subheader("ğŸ“‹ Dá»¯ liá»‡u gá»‘c")
        st.write(df.head())

        # **2ï¸âƒ£ ThÃ´ng tin vá» dá»¯ liá»‡u**
        st.subheader("ğŸ“Š ThÃ´ng tin dá»¯ liá»‡u")
        st.write(f"ğŸ”¹ **Sá»‘ dÃ²ng vÃ  cá»™t**: {df.shape}")
        st.write(f"ğŸ”¹ **CÃ¡c cá»™t**: {df.columns}")
        st.write(f"ğŸ”¹ **Dá»¯ liá»‡u thiáº¿u** (NaN):")
        missing_values = df.isna().sum()
        st.write(missing_values[missing_values > 0])

        # **3ï¸âƒ£ Hiá»ƒn thá»‹ tá»«ng bÆ°á»›c xá»­ lÃ½ dá»¯ liá»‡u**
        st.subheader("ğŸ› ï¸ CÃ¡c bÆ°á»›c xá»­ lÃ½ dá»¯ liá»‡u")

        with st.expander("ğŸ“Œ BÆ°á»›c 1: Loáº¡i bá» cá»™t khÃ´ng cáº§n thiáº¿t"):
            drop_cols = ['Name', 'Ticket', 'Cabin']  # CÃ¡c cá»™t khÃ´ng cáº§n thiáº¿t
            df = df.drop(columns=drop_cols)
            st.write(f"ğŸ”¹ Cá»™t Ä‘Ã£ loáº¡i bá»: {drop_cols}")
            st.write(df.head())

        with st.expander("ğŸ“Œ BÆ°á»›c 2: Xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u"):
            # Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng dá»¯ liá»‡u thiáº¿u trÆ°á»›c khi xá»­ lÃ½
            st.write(f"ğŸ”¹ Dá»¯ liá»‡u thiáº¿u trÆ°á»›c khi xá»­ lÃ½: {df.isna().sum()}")
            
            # Cá»¥ thá»ƒ xá»­ lÃ½ cÃ¡c cá»™t cÃ³ dá»¯ liá»‡u thiáº¿u
            st.write("ğŸ”¹ **Xá»­ lÃ½ cá»™t 'Age'**: Äiá»n giÃ¡ trá»‹ thiáº¿u báº±ng giÃ¡ trá»‹ trung bÃ¬nh (median).")
            df['Age'] = df['Age'].fillna(df['Age'].median())
            
            st.write("ğŸ”¹ **Xá»­ lÃ½ cá»™t 'Embarked'**: Äiá»n giÃ¡ trá»‹ thiáº¿u báº±ng giÃ¡ trá»‹ xuáº¥t hiá»‡n nhiá»u nháº¥t (mode).")
            df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])

            # Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng dá»¯ liá»‡u thiáº¿u sau khi xá»­ lÃ½
            st.write(f"ğŸ”¹ Dá»¯ liá»‡u thiáº¿u sau khi xá»­ lÃ½: {df.isna().sum()}")
            st.write(df.head())

        with st.expander("ğŸ“Œ BÆ°á»›c 3: Chuyá»ƒn Ä‘á»•i One-Hot Encoding vÃ  MÃ£ hÃ³a"):
            # MÃ£ hÃ³a "Sex" theo cÃ¡ch mong muá»‘n
            df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})

            # MÃ£ hÃ³a "Embarked" theo cÃ¡ch mong muá»‘n
            df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})
            
            # Log cÃ¡c tham sá»‘ vÃ o MLflow
            mlflow.log_param("encoded_columns", ['Sex', 'Embarked'])

            # Hiá»ƒn thá»‹ káº¿t quáº£ sau khi mÃ£ hÃ³a
            st.write(f"ğŸ”¹ Sau khi mÃ£ hÃ³a: ")
            st.write(df.head())


        with st.expander("ğŸ“Œ BÆ°á»›c 4: Chuáº©n hÃ³a dá»¯ liá»‡u"):
            # Chuáº©n hÃ³a dá»¯ liá»‡u
            scaler = StandardScaler()
            numerical_cols = ['Age', 'Fare']
            df[numerical_cols] = scaler.fit_transform(df[numerical_cols])
            st.write(f"ğŸ”¹ Dá»¯ liá»‡u sau khi chuáº©n hÃ³a: ")
            st.write(df.head())

        # **4ï¸âƒ£ Hiá»ƒn thá»‹ Dá»¯ liá»‡u Sau Xá»­ LÃ½**
        st.subheader("âœ… Dá»¯ liá»‡u sau xá»­ lÃ½")
        st.write(df.head())

        # **5ï¸âƒ£ Chia táº­p dá»¯ liá»‡u**
        from Buoi2_processing import split_data
        X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(df, target_column="Survived")

        # Hiá»ƒn thá»‹ kÃ­ch thÆ°á»›c táº­p train/val/test
        st.subheader("ğŸ“Š KÃ­ch thÆ°á»›c táº­p dá»¯ liá»‡u sau khi chia")
        st.write(f"ğŸ”¹ **Train:** {X_train.shape} máº«u")
        st.write(f"ğŸ”¹ **Validation:** {X_valid.shape} máº«u")
        st.write(f"ğŸ”¹ **Test:** {X_test.shape} máº«u")

        # Cho phÃ©p táº£i vá» dá»¯ liá»‡u sau xá»­ lÃ½
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button("ğŸ’¾ Táº£i xuá»‘ng dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½", csv, "processed_data.csv", "text/csv")

    # ========================== TAB 2: HUáº¤N LUYá»†N MÃ” HÃŒNH ==========================
    import yaml
    import os

    # ========================== TAB 2: HUáº¤N LUYá»†N MÃ” HÃŒNH ==========================
    with tab2:

        # HÃ m láº¥y thÃ´ng tin tá»« MLflow
        def get_mlflow_runs():
            tracking_uri = "file:./mlruns"
            mlflow.set_tracking_uri(tracking_uri)

            client = mlflow.tracking.MlflowClient()
            experiments = client.search_experiments()

            runs_data = []
            for exp in experiments:
                runs = client.search_runs(exp.experiment_id)
                for run in runs:
                    run_data = run.data.to_dictionary()
                    run_info = {
                        "run_id": run.info.run_id,
                        "experiment_id": run.info.experiment_id,
                        "model_type": run_data["params"].get("model_type", "Unknown"),
                        "params": run_data["params"],
                        "metrics": run_data["metrics"],
                    }
                    runs_data.append(run_info)

            return runs_data if runs_data else None

        st.header("ğŸ“ˆ Káº¿t quáº£ Huáº¥n luyá»‡n MÃ´ hÃ¬nh")

        # Hiá»ƒn thá»‹ kÃ­ch thÆ°á»›c cá»§a táº­p dá»¯ liá»‡u
        st.subheader("ğŸ“Š KÃ­ch thÆ°á»›c táº­p dá»¯ liá»‡u")
        st.write(f"ğŸ”¹ **Train:** {X_train.shape[0]} máº«u, {X_train.shape[1]} features")
        st.write(f"ğŸ”¹ **Validation:** {X_valid.shape[0]} máº«u, {X_valid.shape[1]} features")
        st.write(f"ğŸ”¹ **Test:** {X_test.shape[0]} máº«u, {X_test.shape[1]} features")

        # Chá»n mÃ´ hÃ¬nh Ä‘á»ƒ hiá»ƒn thá»‹ káº¿t quáº£
        model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh Ä‘á»ƒ hiá»ƒn thá»‹ káº¿t quáº£", ["Random Forest", "Linear Regression", "Polynomial Regression"])

        # Láº¥y thÃ´ng tin tá»« MLflow
        runs = get_mlflow_runs()
        if runs is not None:
            filtered_runs = [run for run in runs if run["model_type"] == model_choice]

            if filtered_runs:
                latest_run = filtered_runs[0]  # Láº¥y káº¿t quáº£ má»›i nháº¥t

                st.subheader("ğŸ“Œ Parameters")
                params_df = pd.DataFrame(list(latest_run["params"].items()), columns=["Parameter", "Value"])
                st.dataframe(params_df, width=800)

                st.subheader("ğŸ“Š Metrics")
                metrics_dict = latest_run["metrics"]

                if model_choice == "Random Forest":
                    selected_metrics = [
                        "class_0_f1-score", "class_0_precision", "class_0_recall", "class_0_support",
                        "class_1_f1-score", "class_1_precision", "class_1_recall", "class_1_support",
                        "class_macro avg_f1-score", "class_macro avg_precision", "class_macro avg_recall", "class_macro avg_support",
                        "class_weighted avg_f1-score", "class_weighted avg_precision", "class_weighted avg_recall", "class_weighted avg_support",
                        "fold_1_accuracy", "fold_2_accuracy", "fold_3_accuracy", "fold_4_accuracy", "fold_5_accuracy", "test_accuracy"
                    ]
                elif model_choice == "Linear Regression":
                    selected_metrics = ["fold_1_r2", "fold_2_r2", "fold_3_r2", "fold_4_r2", "fold_5_r2", "test_mse", "test_r2"]
                elif model_choice == "Polynomial Regression":
                    selected_metrics = ["fold_1_r2", "fold_2_r2", "fold_3_r2", "fold_4_r2", "fold_5_r2", "test_mse", "test_r2"]
                else:
                    selected_metrics = []

                metrics_df = pd.DataFrame(
                    [(metric, value) for metric, value in metrics_dict.items() if metric in selected_metrics],
                    columns=["Metric", "Value"]
                )
                st.dataframe(metrics_df, width=1000)

                # ================== NÃºt xem file meta.yaml ==================
                meta_path = f"mlruns/{latest_run['experiment_id']}/{latest_run['run_id']}/meta.yaml"

                if st.button("ğŸ“„ Xem Chi tiáº¿t cá»§a mÃ´ hÃ¬nh nÃ y"):
                    if os.path.exists(meta_path):
                        with open(meta_path, "r", encoding="utf-8") as file:
                            meta_data = yaml.safe_load(file)
                        
                        st.subheader(f"ğŸ“‘ Chi Tiáº¿t cá»§a  {model_choice}")
                        st.json(meta_data)
                    else:
                        st.error("ğŸš¨ KhÃ´ng tÃ¬m tháº¥y file `meta.yaml`. HÃ£y kiá»ƒm tra láº¡i!")
            else:
                st.warning(f"KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u cho mÃ´ hÃ¬nh {model_choice}.")


    # Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n    
    # ========================== TAB 3: Dá»° ÄOÃN ==========================
    with tab3:
        st.header("ğŸš¢ Titanic Survival Prediction")
        st.subheader("ğŸ”¢ Nháº­p ThÃ´ng Tin HÃ nh KhÃ¡ch")
        col1, col2 = st.columns(2)

        with col1:
            pclass = st.selectbox("ğŸ”¹ Pclass", [1, 2, 3])
            sex = st.selectbox("ğŸ”¹ Sex", ["Male", "Female"])
            age = st.number_input("ğŸ”¹ Age", min_value=0, max_value=100, value=30)
            embarked = st.selectbox("ğŸ”¹ Embarked", ["S", "C", "Q"])

        with col2:
            sibsp = st.number_input("ğŸ”¹ SibSp", min_value=0, max_value=10, value=0)
            parch = st.number_input("ğŸ”¹ Parch", min_value=0, max_value=10, value=0)
            fare = st.number_input("ğŸ”¹ Fare", min_value=0.0, max_value=500.0, value=32.0)

        # Tiá»n xá»­ lÃ½ Ä‘áº§u vÃ o
        input_data = preprocess_input(pclass, sex, age, sibsp, parch, fare, embarked)

        # Load mÃ´ hÃ¬nh
        model_paths = {
            "Random Forest": "models/random_forest.pkl",
            "Multiple Regression": "models/linear_regression.pkl",
            "Polynomial Regression": "models/polynomial_regression.pkl"
        }

        models = {
            "Random Forest": load_model_from_file(model_paths["Random Forest"]),
            "Multiple Regression": load_model_from_file(model_paths["Multiple Regression"]),
        }

        # Load riÃªng Polynomial Regression
        poly_model, poly = load_model_from_file(model_paths["Polynomial Regression"])  # TÃ¡ch riÃªng model & PolynomialFeatures
        models["Polynomial Regression"] = poly_model  # LÆ°u model vÃ o dictionary
        input_data_poly = poly.transform(input_data)  # Chuyá»ƒn Ä‘á»•i Ä‘áº§u vÃ o

        # NÃºt dá»± Ä‘oÃ¡n
        if st.button("ğŸš€ Predict Survival"):
            results = {}
            for model_name, model in models.items():
                if model_name == "Polynomial Regression":
                    pred = model.predict(input_data_poly)[0]  # Dá»± Ä‘oÃ¡n vá»›i input Ä‘Ã£ biáº¿n Ä‘á»•i
                else:
                    pred = model.predict(input_data)[0]
                results[model_name] = "ğŸŸ¢ Survived" if pred == 1 else "ğŸ”´ Did Not Survive"

            # Hiá»ƒn thá»‹ káº¿t quáº£ tá»« cáº£ 3 mÃ´ hÃ¬nh
            st.subheader("ğŸ“Š Káº¿t quáº£ Dá»± Ä‘oÃ¡n")
            for model_name, result in results.items():
                st.write(f"ğŸ”¹ **{model_name}**: {result}")


if __name__ == "__main__":
    main()
